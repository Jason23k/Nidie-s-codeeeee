# # datasets/sliced_coco.py
# import torch
# import numpy as np
# from PIL import Image
# import os
# import random
# from sahi.slicing import slice_image
# from sahi.utils.coco import CocoAnnotation


# class SlicedCocoDetection(torch.utils.data.Dataset):
#     def __init__(
#         self,
#         img_folder,
#         ann_file,
#         transforms,
#         slice_size=640,
#         overlap_ratio=0.2,
#         small_obj_threshold=900,
#         return_original_prob=0.3,
#         return_masks=False,
#     ):
#         from .coco import CocoDetection
#         # åˆå§‹åŒ–åŸå§‹ coco æ•°æ®é›†ï¼ˆä¸ä¼  transformsï¼ï¼‰
#         self.coco_ds = CocoDetection(
#             img_folder=img_folder,
#             ann_file=ann_file,
#             transforms=None,          # â† å…³é”®ï¼šä¸è‡ªåŠ¨ transform
#             return_masks=return_masks
#         )
#         self.transforms = transforms
#         self.slice_size = slice_size
#         self.overlap_ratio = overlap_ratio
#         self.small_obj_threshold = small_obj_threshold
#         self.return_original_prob = return_original_prob

#     def __len__(self):
#         return len(self.coco_ds)

#     def __getitem__(self, idx):
#         # è·å–åŸå§‹æ•°æ®ï¼ˆPIL Image + åŸå§‹ targetï¼‰
#         original_img, original_target = self.coco_ds[idx]  # â† è¿™é‡Œ img æ˜¯ PILï¼

#         # å†³å®šæ˜¯å¦ä½¿ç”¨åŸå§‹å›¾åƒ or åˆ‡ç‰‡
#         if random.random() < self.return_original_prob:
#             img, target = original_img, original_target
#         else:
#             img, target = self._sahi_slice_sample(original_img, original_target)

#         # æœ€åç»Ÿä¸€åº”ç”¨ transforms
#         if self.transforms is not None:
#             img, target = self.transforms(img, target)

#         return img, target

#     def _sahi_slice_sample(self, pil_img, target):
#         boxes = target["boxes"]
#         labels = target["labels"]
#         image_id = target["image_id"]

#         # è½¬ CocoAnnotationï¼ˆxyxyï¼‰
#         coco_annotations = []
#         for box, label in zip(boxes, labels):
#             x1, y1, x2, y2 = box.tolist()
#             if x2 <= x1 or y2 <= y1:
#                 continue
#             ann = CocoAnnotation(
#                 bbox=[x1, y1, x2, y2],
#                 category_id=int(label),
#                 category_name="object"
#             )
#             coco_annotations.append(ann)

#         # åˆ‡ç‰‡ï¼šå…³é”®ï¼è®¾ç½® image_dir=None é˜²æ­¢å†™ç£ç›˜ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
#         slice_result = slice_image(
#             image=pil_img,
#             coco_annotation_list=coco_annotations,
#             slice_height=self.slice_size,
#             slice_width=self.slice_size,
#             overlap_height_ratio=self.overlap_ratio,
#             overlap_width_ratio=self.overlap_ratio
#             # keep_empty_slices=False,
#             # image_dir=None  # ğŸ‘ˆ ä¸ä¿å­˜å›¾åƒåˆ°ç£ç›˜
#         )

#         # ç°åœ¨ï¼šslice_result.images å’Œ slice_result.coco_images é•¿åº¦ç›¸åŒï¼Œä¸€ä¸€å¯¹åº”
#         if len(slice_result.coco_images) == 0:
#             return pil_img, target

#         # æ‰¾å‡ºéç©ºåˆ‡ç‰‡çš„ç´¢å¼•
#         valid_indices = [
#             i for i, ci in enumerate(slice_result.coco_images)
#             if len(ci.annotations) > 0
#         ]

#         if not valid_indices:
#             return pil_img, target

#         # éšæœºé€‰ä¸€ä¸ªæœ‰æ•ˆç´¢å¼•
#         idx = random.choice(valid_indices)
#         sliced_img = slice_result.images[idx]          # PIL.Image âœ…
#         sliced_anns = slice_result.coco_images[idx].annotations  # List[CocoAnnotation] âœ…

#         # è¿‡æ»¤å°ç›®æ ‡
#         new_boxes = []
#         new_labels = []
#         for ann in sliced_anns:
#             bbox = ann.bbox
#             w = bbox[2] - bbox[0]
#             h = bbox[3] - bbox[1]
#             if w * h >= self.small_obj_threshold:
#                 new_boxes.append(bbox)
#                 new_labels.append(ann.category_id)

#         if not new_boxes:
#             return pil_img, target

#         new_target = {
#             "image_id": image_id,
#             "boxes": torch.as_tensor(new_boxes, dtype=torch.float32),
#             "labels": torch.as_tensor(new_labels, dtype=torch.int64),
#             "orig_size": torch.as_tensor([sliced_img.height, sliced_img.width]),
#             "size": torch.as_tensor([sliced_img.height, sliced_img.width]),
#         }

#         return sliced_img, new_target

# create_sliced_coco.py
# import os
# from sahi.utils.coco import Coco
# from sahi.utils.file import save_json
# from sahi.slicing import slice_coco

# def create_sliced_coco_dataset(
#     coco_annotation_path: str,
#     image_dir: str,
#     output_dir: str,
#     slice_height: int = 640,
#     slice_width: int = 640,
#     overlap_height_ratio: float = 0.2,
#     overlap_width_ratio: float = 0.2,
#     min_area_ratio: float = 0.1,
#     verbose: bool = True
# ):
#     """
#     ä½¿ç”¨ SAHI å¯¹ COCO æ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ï¼Œç”Ÿæˆæ–°çš„ COCO æ ¼å¼æ•°æ®é›†ã€‚
    
#     Args:
#         coco_annotation_path: åŸå§‹ COCO JSON è·¯å¾„
#         image_dir: åŸå§‹å›¾åƒç›®å½•
#         output_dir: åˆ‡ç‰‡è¾“å‡ºç›®å½•ï¼ˆä¼šåˆ›å»º images/ å’Œ annotations.jsonï¼‰
#         slice_height/width: åˆ‡ç‰‡å°ºå¯¸
#         overlap_*_ratio: é‡å æ¯”ä¾‹ [0, 1)
#         min_area_ratio: å°äºè¯¥æ¯”ä¾‹çš„æ ‡æ³¨ä¼šè¢«è¿‡æ»¤ï¼ˆé˜²æ­¢åˆ‡ç¢å°ç›®æ ‡ï¼‰
#     """
#     # åˆ›å»ºè¾“å‡ºç›®å½•
#     sliced_image_dir = os.path.join(output_dir, "images")
#     os.makedirs(sliced_image_dir, exist_ok=True)

#     # æ‰§è¡Œåˆ‡ç‰‡
#     coco_dict, _ = slice_coco(
#         coco_annotation_file_path=coco_annotation_path,
#         image_dir=image_dir,
#         output_dir=sliced_image_dir,
#         slice_height=slice_height,
#         slice_width=slice_width,
#         overlap_height_ratio=overlap_height_ratio,
#         overlap_width_ratio=overlap_width_ratio,
#         min_area_ratio=min_area_ratio,
#         verbose=verbose,
#     )

#     # ä¿å­˜æ–°çš„ COCO JSON
#     output_json_path = os.path.join(output_dir, "annotations.json")
#     save_json(coco_dict, output_json_path)

#     print(f"âœ… åˆ‡ç‰‡å®Œæˆï¼\n - å›¾åƒ: {sliced_image_dir}\n - æ ‡æ³¨: {output_json_path}")
#     return output_json_path, sliced_image_dir

# create_sliced_coco.py
# create_sliced_coco.py (for sahi==0.11.36)
import os
from sahi.slicing import slice_coco

def create_sliced_coco_dataset(
    coco_annotation_path: str,
    image_dir: str,
    output_dir: str,
    slice_height: int = 640,
    slice_width: int = 640,
    overlap_height_ratio: float = 0.2,
    overlap_width_ratio: float = 0.2,
    min_area_ratio: float = 0.1,
    verbose: bool = True
):
    """
    ä¸“ä¸º SAHI v0.11.36 è®¾è®¡çš„ COCO åˆ‡ç‰‡å‡½æ•°ã€‚
    """
    os.makedirs(output_dir, exist_ok=True)

    # è°ƒç”¨ slice_cocoï¼ˆæ³¨æ„å‚æ•°é¡ºåºå’Œå«ä¹‰ï¼‰
    coco_dict, _ = slice_coco(
        coco_annotation_file_path=coco_annotation_path,
        image_dir=image_dir,
        output_coco_annotation_file_name="annotations.json",  # åªæ˜¯æ–‡ä»¶åï¼
        output_dir=output_dir,  # å›¾åƒå’Œ JSON éƒ½ä¼šæ”¾åœ¨è¿™é‡Œ
        slice_height=slice_height,
        slice_width=slice_width,
        overlap_height_ratio=overlap_height_ratio,
        overlap_width_ratio=overlap_width_ratio,
        min_area_ratio=min_area_ratio,
        verbose=verbose,
    )

    # SAHI 0.11.36 ä¼šè‡ªåŠ¨æŠŠ annotations.json å†™å…¥ output_dir
    sliced_image_dir = output_dir  # å› ä¸ºå›¾åƒä¹Ÿç›´æ¥å­˜åˆ° output_dir æ ¹ä¸‹
    output_json_path = os.path.join(output_dir, "annotations.json")

    print(f"âœ… SAHI 0.11.36 åˆ‡ç‰‡å®Œæˆï¼\n - å›¾åƒ & æ ‡æ³¨ç›®å½•: {output_dir}")
    return output_json_path, sliced_image_dir